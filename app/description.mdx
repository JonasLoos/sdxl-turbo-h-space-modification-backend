
---

## How this works

The prompt is formed by the *base prompt* and *prompt continuation* from above and then send to a [SDXL-Turbo](https://huggingface.co/stabilityai/sdxl-turbo) model. The h-space of the model, which is in the bottom of the unet, is then adjusted during the image generation process. For this adjustment, a precomputed direction is scaled by the given scales from above and added. The direction is computed by running the model multiple times with a base prompt and an adjusted prompt and then taking the average h-space difference between the two.

Here is some example code:

```python
def get_representation(text, count):
    reprs = []
    def get_repr(module, input, output):
        reprs.append(output.detach())
    for i in range(count):
        with torch.no_grad(), pipe.unet.mid_block.register_forward_hook(get_repr):
            pipe(prompt = text, num_inference_steps = 1, guidance_scale=0.0)
    return torch.cat(reprs).mean(axis=0).cpu()
```

You can check out the source code for this Project on Github: [Webapp](https://github.com/JonasLoos/sdxl-turbo-h-space-modification-backend) and [Model](https://github.com/JonasLoos/sdxl-turbo-h-space-modification-model). Furthermore, this project uses [replicate](https://replicate.com/) for running a modified [SDXL-Turbo](https://huggingface.co/stabilityai/sdxl-turbo) model, and [Vercel](https://vercel.com/) for webapp deployment.

```
